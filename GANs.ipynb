{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0uuryq_F1YC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5WaVsYqGFi1"
      },
      "source": [
        "from tensorflow import keras\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/archive (13).zip\", \"r\")\n",
        "zip_ref.extractall(\"files\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4f0DVU3gAUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368b6de5-512c-4326-8876-838b23cec792"
      },
      "source": [
        "data = keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=\"/content/files/images\", label_mode=None, image_size=(64, 64), batch_size=32,\n",
        "    shuffle=True\n",
        ").map(lambda x: x/255.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 63565 files belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbs1hDOjPG1u"
      },
      "source": [
        "newpath = r'/content/results' \n",
        "if not os.path.exists(newpath):\n",
        "    os.makedirs(newpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQdGaj29H7ve"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D,BatchNormalization,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IA_qZKsakZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9e49ef-87f6-47ef-89f1-bf3e5578638b"
      },
      "source": [
        "latent_dim = 256\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xcvqFlCHu4r",
        "outputId": "b6e18856-92e0-4c83-d51a-1bdf7beba67f"
      },
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64,64,3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLetjWy8HzJL"
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL3cK8j0H2AV"
      },
      "source": [
        "def discriminator_loss(fake_image,real_image):\n",
        "  real_loss=cross_entropy(tf.ones_like(real_image),real_image)\n",
        "  fake_loss=cross_entropy(tf.zeros_like(fake_image),fake_image)\n",
        "  total_loss=real_loss+fake_loss\n",
        "  return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5CnSqAlIUPQ"
      },
      "source": [
        "def generator_loss(fake_image):\n",
        "  return cross_entropy(tf.ones_like(fake_image),fake_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeiFUxoj8ZY0",
        "outputId": "7c552efc-d7b6-468d-ecd0-908f1f6815e9"
      },
      "source": [
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8192)              2105344   \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       524544    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 512)       2097664   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 64, 64, 3)         38403     \n",
            "=================================================================\n",
            "Total params: 5,028,227\n",
            "Trainable params: 5,028,227\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UZSVntX8cv7",
        "outputId": "5dae23ed-3815-4c98-c122-f8933e9e28f7"
      },
      "source": [
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        3136      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 128)       131200    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 8193      \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glq54C86IuOa"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ocCNaIjZ5ln",
        "outputId": "db89bfb3-7110-4310-fe4b-2b77b3f06f79"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(20):\n",
        "  for idx,real in enumerate(tqdm(data)):\n",
        "    batch_size=real.shape[0]\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      random_latent_vectors = tf.random.normal(shape=(batch_size,latent_dim))\n",
        "      fake_images=generator(random_latent_vectors,training=True)\n",
        "      real_output=discriminator(real,training=True)\n",
        "      fake_output=discriminator(fake_images,training=True)\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss( fake_output,real_output)\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "      if idx%100 ==0:\n",
        "        img = keras.preprocessing.image.array_to_img(fake_images[0])\n",
        "        img.save(\"/content/results/generated_img_%03d_%d.png\" % (epoch, idx))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1987/1987 [12:06<00:00,  2.73it/s]\n",
            " 46%|████▌     | 915/1987 [05:17<06:11,  2.88it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHQWBHGH0SzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}